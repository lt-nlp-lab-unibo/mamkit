{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mamkit.utils' from '/home/stefano/Public/mamkit/mamkit/utils.py'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import mamkit\n",
    "from mamkit.utils import get_audio_dataset\n",
    "from mamkit.datasets import MAMKitMonomodalDataset, BERT_Collator, UnimodalCollator\n",
    "from random import randint\n",
    "from mamkit.models import MAMKitAudioOnly\n",
    "import lightning as L\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from mamkit.utils import to_lighting_model, MetricTracker\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "import importlib\n",
    "importlib.reload(mamkit.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset wav2vec2-single...\n",
      "Dataset wav2vec2-single downloaded.\n",
      "Extracting dataset wav2vec2-single...\n",
      "Dataset wav2vec2-single extracted.\n",
      "Lengths:  9455 5201 5908\n"
     ]
    }
   ],
   "source": [
    "# ACC\n",
    "LABELS_TO_INT = {\n",
    "    'Claim': 0,\n",
    "    'Premise': 1,\n",
    "}\n",
    "\n",
    "# ASD\n",
    "# LABELS_TO_INT = {\n",
    "#     'ARG': 0,\n",
    "#     'Not-ARG': 1,\n",
    "# }\n",
    "\n",
    "train, val, test = get_audio_dataset('usdbelec', 'wav2vec2-single', 'acc')\n",
    "print(\"Lengths: \", len(train), len(val), len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_collator(labels):\n",
    "    return torch.tensor([LABELS_TO_INT[label] for label in labels])\n",
    "\n",
    "def audio_collate_fn(features):\n",
    "    features = pad_sequence(features, batch_first=True, padding_value=float('-inf'))\n",
    "    attention_mask = features[:, :, 0] != float('-inf')\n",
    "    features[(features == float('-inf'))] = 0\n",
    "    return features, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimodal_collator = UnimodalCollator(\n",
    "    features_collator = audio_collate_fn,\n",
    "    label_collator = label_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train, batch_size=8, shuffle=False, collate_fn=unimodal_collator)\n",
    "val_dataloader = torch.utils.data.DataLoader(val, batch_size=8, shuffle=False, collate_fn=unimodal_collator)\n",
    "test_dataloader = torch.utils.data.DataLoader(test, batch_size=8, shuffle=False, collate_fn=unimodal_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | MAMKitAudioOnly  | 7.7 K \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "2 | val_metrics   | ModuleList       | 0     \n",
      "3 | test_metrics  | ModuleList       | 0     \n",
      "---------------------------------------------------\n",
      "7.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1182/1182 [00:22<00:00, 52.69it/s, v_num=48, train_loss=0.659, val_loss=0.745, Accuracy=0.541, F1=0.541]\n",
      "\n",
      "Epoch 1: 100%|██████████| 1182/1182 [00:22<00:00, 52.88it/s, v_num=48, train_loss=0.659, val_loss=0.745, Accuracy=0.541, F1=0.541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1: 100%|██████████| 1182/1182 [00:22<00:00, 52.85it/s, v_num=48, train_loss=0.659, val_loss=0.745, Accuracy=0.541, F1=0.541]\n"
     ]
    }
   ],
   "source": [
    "classification_head = torch.nn.Sequential(\n",
    "    torch.nn.Linear(768, 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 2)\n",
    ")\n",
    "\n",
    "audio_only = MAMKitAudioOnly(\n",
    "    head = classification_head,\n",
    ")\n",
    "\n",
    "val_metrics = {\"Val_Accuracy\":torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2), \"Val_F1\":torchmetrics.classification.F1Score(task=\"multiclass\", num_classes=2)}\n",
    "test_metrics = {\"Test_Accuracy\":torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2), \"Test_F1\":torchmetrics.classification.F1Score(task=\"multiclass\", num_classes=2)}\n",
    "\n",
    "model = to_lighting_model(audio_only, torch.nn.CrossEntropyLoss(), torch.optim.Adam, lr=1e-3, val_metrics=val_metrics, test_metrics=test_metrics, log_metrics=True)\n",
    "\n",
    "mt = MetricTracker()\n",
    "\n",
    "trainer = L.Trainer(max_epochs=2, check_val_every_n_epoch=1, callbacks=[mt])\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': tensor(0.6818),\n",
       "  'Accuracy': tensor(0.4375),\n",
       "  'F1': tensor(0.4375)},\n",
       " {'train_loss': tensor(0.6593),\n",
       "  'val_loss': tensor(0.7453),\n",
       "  'Accuracy': tensor(0.5414),\n",
       "  'F1': tensor(0.5414)},\n",
       " {'train_loss': tensor(0.6593),\n",
       "  'val_loss': tensor(0.7453),\n",
       "  'Accuracy': tensor(0.5414),\n",
       "  'F1': tensor(0.5414)}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 651/651 [00:07<00:00, 85.37it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5414343476295471     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            F1             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5414343476295471     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5414343476295471    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m           F1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5414343476295471    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_results = trainer.validate(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   1%|          | 8/739 [00:00<00:07, 96.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 739/739 [00:07<00:00, 94.41it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       Val_Accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5140487551689148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          Val_F1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5140487551689148     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           loss            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6930490732192993     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      Val_Accuracy       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5140487551689148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         Val_F1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5140487551689148    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          loss           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6930490732192993    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results = trainer.test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Accuracy': 0.5140487551689148,\n",
       "  'F1': 0.5140487551689148,\n",
       "  'loss': 0.6929669380187988}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
